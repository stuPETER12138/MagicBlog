<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.52" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <title>Datawhale AI 夏令营（第二期） Task 2 学习笔记</title><meta name="description" content="">
    <link rel="preload" href="/assets/style-BNzY1Zho.css" as="style"><link rel="stylesheet" href="/assets/style-BNzY1Zho.css">
    <link rel="modulepreload" href="/assets/app-B1x6Xc0P.js"><link rel="modulepreload" href="/assets/task0202.html-qJU1hr5F.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-CH6LiQfx.js" as="script"><link rel="prefetch" href="/assets/index.html-D1BIPhZ7.js" as="script"><link rel="prefetch" href="/assets/task0201.html-CZ63QeHJ.js" as="script"><link rel="prefetch" href="/assets/task0203.html-DtMVyepw.js" as="script"><link rel="prefetch" href="/assets/001.html-BFEomD2R.js" as="script"><link rel="prefetch" href="/assets/index.html-BV7RGYXz.js" as="script"><link rel="prefetch" href="/assets/index.html-Bv14Drm4.js" as="script"><link rel="prefetch" href="/assets/latex.html-_YisUtOe.js" as="script"><link rel="prefetch" href="/assets/learningmd.html-DDDLnR6c.js" as="script"><link rel="prefetch" href="/assets/manim_tutor.html-GZuSeDAn.js" as="script"><link rel="prefetch" href="/assets/index.html-0srA0X-z.js" as="script"><link rel="prefetch" href="/assets/Tutor.html-Bmwee0Cq.js" as="script"><link rel="prefetch" href="/assets/index.html-CirfVxAu.js" as="script"><link rel="prefetch" href="/assets/DS-MoE.html-CLR_4au-.js" as="script"><link rel="prefetch" href="/assets/index.html-DjuoQnUi.js" as="script"><link rel="prefetch" href="/assets/404.html-B4IxYJ8k.js" as="script"><link rel="prefetch" href="/assets/index.html-CZBaY7aK.js" as="script"><link rel="prefetch" href="/assets/index.html-C6va63n5.js" as="script"><link rel="prefetch" href="/assets/index.html-BGRrEMqV.js" as="script"><link rel="prefetch" href="/assets/index.html-DqpCbXc5.js" as="script"><link rel="prefetch" href="/assets/index.html-CYf_7jGK.js" as="script"><link rel="prefetch" href="/assets/index.html-DeM5YYSO.js" as="script"><link rel="prefetch" href="/assets/index.html-B_0833x3.js" as="script"><link rel="prefetch" href="/assets/index.html-DwLrofLd.js" as="script"><link rel="prefetch" href="/assets/index.html-DoZe55YW.js" as="script"><link rel="prefetch" href="/assets/index.html-LwAfc2Us.js" as="script"><link rel="prefetch" href="/assets/index.html-CzQEf3pi.js" as="script"><link rel="prefetch" href="/assets/index.html-CX3uLkRX.js" as="script"><link rel="prefetch" href="/assets/index.html-DrF_baV3.js" as="script"><link rel="prefetch" href="/assets/index.html-DcOHS2ey.js" as="script"><link rel="prefetch" href="/assets/index.html-CLfrd_2c.js" as="script"><link rel="prefetch" href="/assets/browser-DFdoOzbh.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-GXRgw7eJ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/"><img class="vp-nav-logo" src="/images/magicsquash.jpg" alt><!----><!----></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="主页"><!--[--><img class="icon" src="/icons/svg-spinners--blocks-scale.svg" alt aria-hidden no-view style=""><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="我学"><!--[--><img class="icon" src="/icons/line-md--coffee-loop.svg" alt aria-hidden no-view style="">我学<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">文档撰写指北</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/studying/markdown/latex.html" aria-label="latex 语法指北"><!---->latex 语法指北<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/studying/markdown/learningmd.html" aria-label="markdown 语法指北"><!---->markdown 语法指北<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/studying/markdown/manim_tutor.html" aria-label="Manim 语法指北"><!---->Manim 语法指北<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">一点点 VIM</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/studying/vim/Tutor.html" aria-label="VIM 基础教程"><!---->VIM 基础教程<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="我思"><!--[--><img class="icon" src="/icons/line-md--speedometer-loop.svg" alt aria-hidden no-view style="">我思<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">论文精读</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/thinking/papereading/DS-MoE.html" aria-label="DeepSpeed-MoE 阅读笔记"><!---->DeepSpeed-MoE 阅读笔记<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">我的大学</h4><ul class="vp-dropdown-subitems"></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="我做"><!--[--><img class="icon" src="/icons/line-md--cog-loop.svg" alt aria-hidden no-view style="">我做<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">晋馔雅韵</h4><ul class="vp-dropdown-subitems"></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Datawhale AI 夏令营</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/doing/DatawhaleAI/task0201.html" aria-label="task0201"><!---->task0201<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/doing/DatawhaleAI/task0202.html" aria-label="task0202"><!---->task0202<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/doing/DatawhaleAI/task0203.html" aria-label="task0203"><!---->task0203<!----></a></li></ul></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/stuPETER12138/stuPETER12138.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:none;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:block;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="带我回家"><!---->带我回家<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><!----><span class="vp-sidebar-title">我学</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">VIM 食用指北</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">文档撰写指北</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><!----><span class="vp-sidebar-title">我思</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">窝的大学</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">论文精读</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><!----><span class="vp-sidebar-title">我做</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Datawhale AI 夏令营--学习笔记</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/doing/DatawhaleAI/" aria-label="Datawhale AI 夏令营--学习笔记"><!---->Datawhale AI 夏令营--学习笔记<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/doing/DatawhaleAI/task0201.html" aria-label="Datawhale AI 夏令营（第二期） Task 1 学习笔记"><!---->Datawhale AI 夏令营（第二期） Task 1 学习笔记<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/doing/DatawhaleAI/task0202.html" aria-label="Datawhale AI 夏令营（第二期） Task 2 学习笔记"><!---->Datawhale AI 夏令营（第二期） Task 2 学习笔记<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/doing/DatawhaleAI/task0203.html" aria-label="Datawhale AI 夏令营（第二期） Task 3 学习笔记"><!---->Datawhale AI 夏令营（第二期） Task 3 学习笔记<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">晋馔雅韵</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Datawhale AI 夏令营（第二期） Task 2 学习笔记</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://stupeter12138.github.io" target="_blank" rel="noopener noreferrer">魔法窝瓜</a></span><span property="author" content="魔法窝瓜"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-07-15T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 10 分钟</span><meta property="timeRequired" content="PT10M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color8" role>我做</span><!--]--><meta property="articleSection" content="我做"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color3" role>datawhale</span><span class="page-tag-item color5 clickable" role="navigation">AI</span><!--]--><meta property="keywords" content="datawhale,AI"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#写在前面">写在前面</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#关于环境配置">关于环境配置</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#关于数据处理">关于数据处理</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#关于模型训练">关于模型训练</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#关于质量评价">关于质量评价</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#参考资料">参考资料</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content"><p>Task 2: baseline 代码<sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup>详解入门深度学习</p><h3 id="写在前面" tabindex="-1"><a class="header-anchor" href="#写在前面"><span>写在前面</span></a></h3><p>通常我们基于神经网络解决机器翻译任务的流程如下：</p><figure><img src="https://gitee.com/stu-peter_0/picgopic/raw/main/pictures/20240717174552.png" alt="流程图" tabindex="0" loading="lazy"><figcaption>流程图</figcaption></figure><h3 id="关于环境配置" tabindex="-1"><a class="header-anchor" href="#关于环境配置"><span>关于环境配置</span></a></h3><p><code>魔塔</code>平台已经提供了 Ubutu22.04 + CUDA12.1.0 + python3.10 + pytorch2.3.0 + TensorFlow2.14.0 的预装环境。不过为实现 Task 2，我们还需要额外添加一些库。</p><p>安装 <code>torchtext</code>, <code>jieba</code>, <code>sacrebleu</code>:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pip install torchtext    </span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pip install jieba</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pip install sacrebleu</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>安装<code>spacy</code>，这会是比较“麻烦”的一步。</p><ul><li>网络顺畅请使用：https://spacy.io/usage 。（毕竟是外国网站，速度可想而知</li><li>更推荐使用：离线安装。首先在终端查看更适合自己体质的 spacy 版本：<code>pip show spacy</code>。然后去找<a href="https://github.com/explosion/spacy-models/releases" target="_blank" rel="noopener noreferrer">对应版本的语言包</a>。接下来，将下载到本地的压缩包上传到魔搭平台上的 dataset 目录下（文件较大，上传需要一定时间）。最后，一键安装：<code>pip install ../dataset/en_core_web_[一个代号]-[版本号]-py3-none-any.whl</code></li></ul><p>至此，我们便可以在平台上跑代码了。</p><h3 id="关于数据处理" tabindex="-1"><a class="header-anchor" href="#关于数据处理"><span>关于数据处理</span></a></h3><p>数据处理可以保证模型有效的学习到源语言到目标语言的映射。常见的步骤有：<strong>清洗与规范化</strong>，<strong>分词</strong>，<strong>构建词汇表与词向量</strong>，<strong>序列截断与填充</strong>，<strong>添加特殊标记</strong>，<strong>数据增强</strong>，<strong>数据分割</strong>等。</p><p>值得注意的是，在 baseline 中，使用<code>jieba</code>与<code>spacy</code>分别为中英文进行分词。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">en_tokenizer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> get_tokenizer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;spacy&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">language</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;en_core_web_trf&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">zh_tokenizer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> lambda</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> x</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">list</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(jieba.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">cut</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x))</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>并从训练数据中收集所有出现过的词汇，构建<em>词汇表</em>，并为每个词分配一个唯一的索引。</p><p>同时添加了<em>特殊标记</em>：</p><ol><li>在序列两端添加<code>&lt;BOS&gt;</code>（Sequence Start）和<code>&lt;EOS&gt;</code>（Sequence End）标记，帮助模型识别序列的起始和结束。</li><li>为不在词汇表中的词添加<code>&lt;UNK&gt;</code>（Unknown）标记，使模型能够处理未见过的词汇。</li></ol><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> build_vocab</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">data</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF;"> List[Tuple[List[</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">str</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF;">], List[</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">str</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF;">]]]</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    en_vocab </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> build_vocab_from_iterator</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        (en </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> en, _ </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> data),</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">        specials</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;unk&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;pad&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;bos&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;eos&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    )</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    zh_vocab </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> build_vocab_from_iterator</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        (zh </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> _, zh </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> data),</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">        specials</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;unk&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;pad&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;bos&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;eos&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    )</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    en_vocab.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">set_default_index</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(en_vocab[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;unk&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">])</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    zh_vocab.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">set_default_index</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(zh_vocab[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;unk&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">])</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> en_vocab, zh_vocab</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">class</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> TranslationDataset</span><span style="--shiki-light:#C18401;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">Dataset</span><span style="--shiki-light:#C18401;--shiki-dark:#ABB2BF;">)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> __init__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#E5C07B;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> data</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF;"> List[Tuple[List[</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">str</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF;">], List[</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">str</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF;">]]]</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> en_vocab</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> zh_vocab</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.data </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> data</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.en_vocab </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> en_vocab</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.zh_vocab </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> zh_vocab</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> __len__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#E5C07B;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.data)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> __getitem__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#E5C07B;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> idx</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        en, zh </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.data[idx]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        en_indices </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.en_vocab[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;bos&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.en_vocab[token] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> token </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> en] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.en_vocab[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;eos&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        zh_indices </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.zh_vocab[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;bos&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.zh_vocab[token] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> token </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> zh] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.zh_vocab[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;eos&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]]</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> en_indices, zh_indices</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在处理批次数据时，进行<em>序列填充</em>，确保所有序列长度相同。通常使用<code>&lt;PAD&gt;</code>标记填充。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> collate_fn</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">batch</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    en_batch, zh_batch </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [], []</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> en_item, zh_item </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> batch:</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> en_item </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">and</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> zh_item:  </span><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 确保两个序列都不为空</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">            # print(&quot;都不为空&quot;)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            en_batch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(en_item))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            zh_batch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(zh_item))</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        else</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">            print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;存在为空&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    if</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> not</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> en_batch </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">or</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> not</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> zh_batch:  </span><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 如果整个批次为空，返回空张量</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([]), torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([])</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    en_batch </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.utils.rnn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">pad_sequence</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(en_batch, </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">batch_first</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">padding_value</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">en_vocab[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;pad&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">])</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    zh_batch </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.utils.rnn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">pad_sequence</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(zh_batch, </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">batch_first</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">padding_value</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">zh_vocab[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;pad&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">])</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> en_batch, zh_batch</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="关于模型训练" tabindex="-1"><a class="header-anchor" href="#关于模型训练"><span>关于模型训练</span></a></h3><p><strong>编码器-解码器框架</strong>在神经机器翻译中有着重要地位。它可以将源语言编码为类似信息传输中的数字信号，然后利用解码器对其进行转换，生成目标语言。</p><figure><img src="https://gitee.com/stu-peter_0/picgopic/raw/main/pictures/20240717175019.png" alt="一个运用编码器解码器结构的例子" tabindex="0" loading="lazy"><figcaption>一个运用编码器解码器结构的例子</figcaption></figure><ul><li><p><strong>编码器</strong>？在当今主流的神经机器翻译系统中，编码器由词嵌入层和中间网络层组成。当输入一串单词序列时，词嵌入层（embedding）会将每个单词映射到多维实数表示空间，这个过程也被称为词嵌入。之后中间层会对词嵌入向量进行更深层的抽象，得到输入单词序列的中间表示。</p></li><li><p><strong>解码器</strong>？解码器的结构基本上和编码器是一致的，在基于循环神经网络的翻译模型中，解码器只比编码器多了输出层，用于输出每个目标语言位置的单词生成概率。而在基于自注意力机制的翻译模型中，除了输出层，解码器还比编码器多一个编码­解码注意力子层，用于帮助模型更好地利用源语言信息。</p></li><li><p><strong>注意力机制</strong>！注意力机制的引入使得不再需要把原始文本中的所有必要信息压缩到一个向量当中。</p></li></ul><figure><img src="https://gitee.com/stu-peter_0/picgopic/raw/main/pictures/20240717175201.png" alt="引入注意力机制的循环神经网络机器翻译架构" tabindex="0" loading="lazy"><figcaption>引入注意力机制的循环神经网络机器翻译架构</figcaption></figure><p>传统的 Seq2Seq 模型在解码阶段仅依赖于编码器产生的最后一个隐藏状态，这在处理长序列时效果不佳。注意力机制允许解码器在生成每个输出词时，关注编码器产生的所有中间状态，从而更好地利用源序列的信息。具体来说，给定源语言序列经过编码器输出的向量序列 $h_{1},h_{2},h_{3},...,h_{m}$，注意力机制旨在依据解码端翻译的需要，自适应地从这个向量序列中查找对应的信息。</p><p>值得注意的是，baseline 的代码<sup class="footnote-ref"><a href="#footnote1">[1:1]</a><a class="footnote-anchor" id="footnote-ref1:1"></a></sup>中实现了一个经典的序列到序列（Seq2Seq）模型，中间层使用的 GRU 网络，并且网络中加入了注意力机制（Attention Mechanism）。理论上其对于长序列有着较好的训练结果。</p><p>那么实际如何呢？实验如下：在 baseline 的基础下，规定训练样本为 2000，并在<code>定义常量</code>前增加一个循环，从 10 开始以 5 为步长增加序列长度，最大到 100。将每序列长度及其对应的 BLEU 得分保存在 score_length_list 中。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">score_length_list </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">LENGTH</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 100</span><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">  # 最大句子长度</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> i </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> range</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">LENGTH</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">    MAX_LENGTH</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> i</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">    # 循环包括了定义常量，主函数，在开发集上进行评价等三部分</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">    # 限于篇幅，此处省略，读者可自行尝试与改进</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 然后用 matplotlib 绘图</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> matplotlib.pyplot </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> plt</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> numpy </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> np</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([i[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> i </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> score_length_list], [i[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> i </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> score_length_list])</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">mean_score </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> np.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">mean</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([i[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> i </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> score_length_list])</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">axhline</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">y</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">mean_score, </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">color</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;r&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">linestyle</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;--&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">xlabel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;MAX LENGTH&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ylabel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;BLEU SCORE&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">show</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="https://gitee.com/stu-peter_0/picgopic/raw/main/pictures/20240717175533.png" alt="基于注意力机制的 GRU 神经网络机器翻译" tabindex="0" loading="lazy"><figcaption>基于注意力机制的 GRU 神经网络机器翻译</figcaption></figure><p>可以看出：在 GRU 与注意力机制相结合的情况下，随着句子长度增加，模型也有较可观的得分。受限于样本与循环次数，图线出现了一定波动，但平均值（红色虚线）约为 30。从 10 开始的短序列到 60 以上的长序列，图线的表现相似。可以看出 GRU 与注意力机制相的组合对训练结果确实有所提升。</p><p>不过由于训练样本与训练次数较少，结果可能存在偶然性。为此，我又测试了最大句子长度为 150，200，250 时的 BLEU 分别为：17.14，14.54，10.54。可见 baseline 中 GRU 与注意力机制带来的效果并不会<em>随着句子长度的增加而保持下去</em>。上一部分的实验的结果较为可靠。</p><p>再结合单独使用循环神经网络和循环神经网络加注意力机制。可得<code>注意力机制对于模型训练有较大提升</code>。</p><figure><img src="https://gitee.com/stu-peter_0/picgopic/raw/main/pictures/20240717175224.png" alt="单独使用循环神经网络和循环神经网络加注意力机制" tabindex="0" loading="lazy"><figcaption>单独使用循环神经网络和循环神经网络加注意力机制</figcaption></figure><h4 id="那么-何为-gru" tabindex="-1"><a class="header-anchor" href="#那么-何为-gru"><span>那么，何为 GRU?</span></a></h4><h5 id="一、为什么不是-rnn" tabindex="-1"><a class="header-anchor" href="#一、为什么不是-rnn"><span>一、为什么不是 RNN?</span></a></h5><p>相比普通的 RNN，门控循环单元（GRU）支持隐状态的门控，使得模型有专门的可学习的机制来确定应该何时更新隐状态， 以及应该何时重置隐状态。</p><h5 id="二、重置门与更新们" tabindex="-1"><a class="header-anchor" href="#二、重置门与更新们"><span>二、重置门与更新们</span></a></h5><p>重置门允许我们控制“可能还想记住”的过去状态的数量； 更新门将允许我们控制新状态中有多少个是旧状态的副本。 两个门的输入是由<code>当前时间步的输入</code>和<code>前一时间步的隐状</code>态给出。 两个门的输出是由使用 sigmoid 激活函数的<code>两个全连接层</code>给出。</p><figure><img src="https://gitee.com/stu-peter_0/picgopic/raw/main/pictures/20240717175552.png" alt="在门控循环单元模型中计算重置门和更新门" tabindex="0" loading="lazy"><figcaption>在门控循环单元模型中计算重置门和更新门</figcaption></figure><p>对于确定的时间步 $t$，此时输入（样本个数为 $n$，输入个数为 $d$）为 $X_t$，上一时间步的隐状态（隐藏单元个数为 $h$）是 $H_{t-1}$，则有：</p><p>$$\textstyle R_t = \sum(w_{xr}X_t + w_{hr}H_{t-1} + b_r)$$ $$\textstyle Z_t = \sum(w_{xz}X_t + w_{hz}H_{t-1} + b_z)$$</p><h5 id="三、候选隐状态" tabindex="-1"><a class="header-anchor" href="#三、候选隐状态"><span>三、候选隐状态</span></a></h5><p>将重置门 $R_t$ 与常规隐状态更新机制<sup class="footnote-ref"><a href="#footnote2">[2]</a><a class="footnote-anchor" id="footnote-ref2"></a></sup>集成，得到在时间步 的候选隐状态（candidate hidden state）$\tilde{H_t}$。</p><p>$$\textstyle \tilde{H_t} = tanh(w_{xh}X_t + (R_t \odot H_{t-1})W_{hh} + b_h)$$</p><p>将 $R_t$ 和 $H_{t-1}$ 按元素相乘可以减少以往状态的影响。每当重置门 $R_t$ 中的项接近 1 时，我们可恢复一个普通的循环神经网络<sup class="footnote-ref"><a href="#footnote2">[2:1]</a><a class="footnote-anchor" id="footnote-ref2:1"></a></sup>。对于重置门 $R_t$ 中所有接近 0 的项，候选隐状态是以 $X_t$ 作为输入的多层感知机的结果。因此,任何预先存在的隐状态都会被重置为默认值。</p><figure><img src="https://gitee.com/stu-peter_0/picgopic/raw/main/pictures/20240717175609.png" alt="在门控循环单元模型中计算候选隐状态" tabindex="0" loading="lazy"><figcaption>在门控循环单元模型中计算候选隐状态</figcaption></figure><h5 id="四、隐状态" tabindex="-1"><a class="header-anchor" href="#四、隐状态"><span>四、隐状态</span></a></h5><p>再结合 $Z_t$ 就得出了门控循环单元的最终更新公式：</p><p>$$\textstyle H_t = Z_t \odot H_{t-1} + (1 - Z_t) \odot \tilde{H_t}$$</p><p>每当更新门 $Z_t$ 接近 1 时，模型就倾向只保留旧状态。此时，来自 $X_t$ 的信息基本被忽略，从而有效地跳过了依赖链条中的时间步 $t$。相反，当 $Z_t$ 接近 0 时，新的隐状态 $H_t$ 就会接近候选隐状态 $\tilde{H_t}$。这些可以帮助我们处理循环神经网络中的梯度消失问题，并更好地捕获时间步距离很长的序列的依赖关系。</p><figure><img src="https://gitee.com/stu-peter_0/picgopic/raw/main/pictures/20240717175631.png" alt="计算门控循环单元模型中的隐状" tabindex="0" loading="lazy"><figcaption>计算门控循环单元模型中的隐状</figcaption></figure><p>总而言之，言而总之，门控循环单元，让模型具有了<strong>记忆力</strong>，其具有两大特征：</p><ul><li>重置门有助于捕获序列中的短期依赖关系</li><li>更新门有助于捕获序列中的长期依赖关系</li></ul><h3 id="关于质量评价" tabindex="-1"><a class="header-anchor" href="#关于质量评价"><span>关于质量评价</span></a></h3><p><strong>译文质量评价</strong>，指的是人们用评估系统输出结果的质量的过程。本次夏令营使用的是译文质量自动评价方法 BLEU (Bilingual Evaluation Understudy)，是一种对生成语句进行评估的指标。</p><p><strong>BLEU指标</strong> 常用于衡量计算机生成的翻译与一组参考译文之间的<code>相似度</code>。这个指标特别关注 n-grams（连续的n个词）的精确匹配，可以被认为是对翻译准确性和流利度的一种统计估计。如果生成的翻译中包含的n-grams与参考译文中出现的相同，则认为是匹配的。最终的BLEU分数是一个介于0到1之间的数值，其中1表示与参考译文完美匹配，而0则表示完全没有匹配。</p><p>而对于参赛队伍提交的测试集翻译结果文件，采用自动评价指标<code>BLEU-4</code>进行评价。即考虑<code>连续四个词的匹配</code>情况。可以看出来，BLEU 在测评精度会受常用词的干扰；短译句的测评精度有时会较高，但没有考虑同义词或相似表达的情况，可能会导致合理翻译被否定。所以 baseline 中得到的评分低倒也正常。</p><p>不过好处是：BLEU 属于<code>有参考答案的自动评价</code>。这种自动评价的结果获取成本低，可以多次重复，而且可以用于对系统结果的快速反馈，指导系统优化的方向。</p><figure><img src="https://gitee.com/stu-peter_0/picgopic/raw/main/pictures/20240717175230.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h3><p><a href="https://datawhaler.feishu.cn/wiki/FVs2wAVN5iqHMqk5lW2ckfhAncb?from=from_copylink" target="_blank" rel="noopener noreferrer">Task1：了解机器翻译 &amp; 理解赛题</a></p><p><a href="https://datawhaler.feishu.cn/wiki/PztLwkofsi95oak2Iercw9hkn2g?from=from_copylink" target="_blank" rel="noopener noreferrer">Task2：从baseline代码详解入门深度学习</a></p><p><a href="https://zh.d2l.ai/chapter_recurrent-modern/gru.html" target="_blank" rel="noopener noreferrer">9.1. 门控循环单元（GRU）</a></p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="footnote1" class="footnote-item"><p><a href="https://datawhaler.feishu.cn/wiki/PztLwkofsi95oak2Iercw9hkn2g#WtUhdX63OofXNdxp77NclTVGntb" target="_blank" rel="noopener noreferrer">Task2-baseline.ipynb</a> <a href="#footnote-ref1" class="footnote-backref">↩︎</a> <a href="#footnote-ref1:1" class="footnote-backref">↩︎</a></p></li><li id="footnote2" class="footnote-item"><p><a href="https://zh.d2l.ai/chapter_recurrent-neural-networks/rnn.html#equation-rnn-h-with-state" target="_blank" rel="noopener noreferrer">8.4. 循环神经网络</a> <a href="#footnote-ref2" class="footnote-backref">↩︎</a> <a href="#footnote-ref2:1" class="footnote-backref">↩︎</a></p></li></ol></section></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/stuPETER12138/stuPETER12138.github.io/edit/main/doing/DatawhaleAI/task0202.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">上次编辑于: </span><!----></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: jio12138@qq.com">Wu</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/doing/DatawhaleAI/task0201.html" aria-label="Datawhale AI 夏令营（第二期） Task 1 学习笔记"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->Datawhale AI 夏令营（第二期） Task 1 学习笔记</div></a><a class="route-link auto-link next" href="/doing/DatawhaleAI/task0203.html" aria-label="Datawhale AI 夏令营（第二期） Task 3 学习笔记"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">Datawhale AI 夏令营（第二期） Task 3 学习笔记<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><!----><div class="vp-copyright">MIT 协议 | 版权所有 © 2024 魔法窝瓜</div></footer></div><!--]--><!--]--><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-B1x6Xc0P.js" defer></script>
  </body>
</html>
