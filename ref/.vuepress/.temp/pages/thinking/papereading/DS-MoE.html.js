import comp from "D:/Coding/markdown/stuPETER12138.github.io/ref/.vuepress/.temp/pages/thinking/papereading/DS-MoE.html.vue"
const data = JSON.parse("{\"path\":\"/thinking/papereading/DS-MoE.html\",\"title\":\"DeepSpeed-MoE 阅读笔记\",\"lang\":\"zh-CN\",\"frontmatter\":{\"date\":\"2024-06-29T00:00:00.000Z\",\"title\":\"DeepSpeed-MoE 阅读笔记\",\"star\":1,\"tag\":[\"MoE\",\"AI\"],\"gitInclude\":[]},\"headers\":[{\"level\":3,\"title\":\"摘要\",\"slug\":\"摘要\",\"link\":\"#摘要\",\"children\":[]},{\"level\":3,\"title\":\"引言\",\"slug\":\"引言\",\"link\":\"#引言\",\"children\":[]},{\"level\":3,\"title\":\"相关工作\",\"slug\":\"相关工作\",\"link\":\"#相关工作\",\"children\":[]},{\"level\":3,\"title\":\"DeepSpeed-MoE 用于 NLG：将语言模型训练成本降低 5 倍\",\"slug\":\"deepspeed-moe-用于-nlg-将语言模型训练成本降低-5-倍\",\"link\":\"#deepspeed-moe-用于-nlg-将语言模型训练成本降低-5-倍\",\"children\":[]},{\"level\":3,\"title\":\"PR-MoE 和 MoS：减小模型尺寸并提高参数效率\",\"slug\":\"pr-moe-和-mos-减小模型尺寸并提高参数效率\",\"link\":\"#pr-moe-和-mos-减小模型尺寸并提高参数效率\",\"children\":[]},{\"level\":3,\"title\":\"DeepSpeed-MoE 推理：以空前的规模和速度服务于 MoE 模型\",\"slug\":\"deepspeed-moe-推理-以空前的规模和速度服务于-moe-模型\",\"link\":\"#deepspeed-moe-推理-以空前的规模和速度服务于-moe-模型\",\"children\":[]},{\"level\":3,\"title\":\"展望下一代人工智能规模\",\"slug\":\"展望下一代人工智能规模\",\"link\":\"#展望下一代人工智能规模\",\"children\":[]}],\"readingTime\":{\"minutes\":31.88,\"words\":9563},\"filePathRelative\":\"thinking/papereading/DS-MoE.md\",\"localizedDate\":\"2024年6月29日\",\"excerpt\":\"\"}")
export { comp, data }

if (import.meta.webpackHot) {
  import.meta.webpackHot.accept()
  if (__VUE_HMR_RUNTIME__.updatePageData) {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  }
}

if (import.meta.hot) {
  import.meta.hot.accept(({ data }) => {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  })
}
