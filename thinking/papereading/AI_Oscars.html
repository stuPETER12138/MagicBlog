<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.52" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <title>The Oscars Of AI Theater</title><meta name="description" content="">
    <link rel="preload" href="/assets/style-DED_UGtz.css" as="style"><link rel="stylesheet" href="/assets/style-DED_UGtz.css">
    <link rel="modulepreload" href="/assets/app-z8a553x4.js"><link rel="modulepreload" href="/assets/AI_Oscars.html-3CFOaVDj.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-FdLtR4QC.js" as="script"><link rel="prefetch" href="/assets/index.html-fxHAC9do.js" as="script"><link rel="prefetch" href="/assets/task0201.html-CCCQcpwA.js" as="script"><link rel="prefetch" href="/assets/task0202.html-XQYx40rq.js" as="script"><link rel="prefetch" href="/assets/task0203.html-D-WeRV52.js" as="script"><link rel="prefetch" href="/assets/001.html-DiscyKFm.js" as="script"><link rel="prefetch" href="/assets/index.html-BQ63IFG0.js" as="script"><link rel="prefetch" href="/assets/index.html-D3Jbri7N.js" as="script"><link rel="prefetch" href="/assets/latex.html-BB9zj5wv.js" as="script"><link rel="prefetch" href="/assets/learningmd.html-Bd6ClCL-.js" as="script"><link rel="prefetch" href="/assets/manim_tutor.html-kSjYe-ns.js" as="script"><link rel="prefetch" href="/assets/index.html-Sw3_eT1s.js" as="script"><link rel="prefetch" href="/assets/Tutor.html-Bm6V47lC.js" as="script"><link rel="prefetch" href="/assets/index.html-yJZffjVz.js" as="script"><link rel="prefetch" href="/assets/DS-MoE.html-Dgxu1Mtj.js" as="script"><link rel="prefetch" href="/assets/index.html-Ct1eKASB.js" as="script"><link rel="prefetch" href="/assets/404.html-D0WjQSJH.js" as="script"><link rel="prefetch" href="/assets/index.html-Dlp3Sjvq.js" as="script"><link rel="prefetch" href="/assets/index.html-DBzlnlYj.js" as="script"><link rel="prefetch" href="/assets/index.html-CydpdccD.js" as="script"><link rel="prefetch" href="/assets/index.html-DipqRe2Z.js" as="script"><link rel="prefetch" href="/assets/index.html-C6hiF_Yw.js" as="script"><link rel="prefetch" href="/assets/index.html-D12tAweO.js" as="script"><link rel="prefetch" href="/assets/index.html-WtK0wytE.js" as="script"><link rel="prefetch" href="/assets/index.html-BqhF8XZ7.js" as="script"><link rel="prefetch" href="/assets/index.html-BXPfQ5RS.js" as="script"><link rel="prefetch" href="/assets/index.html-UCVidAcg.js" as="script"><link rel="prefetch" href="/assets/index.html-s4shQEf_.js" as="script"><link rel="prefetch" href="/assets/index.html-B1J_ST__.js" as="script"><link rel="prefetch" href="/assets/index.html-yt6grF10.js" as="script"><link rel="prefetch" href="/assets/index.html-uexog98Y.js" as="script"><link rel="prefetch" href="/assets/index.html-CNskE9v1.js" as="script"><link rel="prefetch" href="/assets/browser-DFdoOzbh.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-GXRgw7eJ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/"><img class="vp-nav-logo" src="/images/magicsquash.jpg" alt><!----><!----></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="主页"><!--[--><img class="icon" src="/icons/svg-spinners--blocks-scale.svg" alt aria-hidden no-view style=""><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="我学"><!--[--><img class="icon" src="/icons/line-md--coffee-loop.svg" alt aria-hidden no-view style="">我学<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">文档撰写指北</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/studying/markdown/latex.html" aria-label="latex 语法指北"><!---->latex 语法指北<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/studying/markdown/learningmd.html" aria-label="markdown 语法指北"><!---->markdown 语法指北<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/studying/markdown/manim_tutor.html" aria-label="Manim 语法指北"><!---->Manim 语法指北<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">一点点 VIM</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/studying/vim/Tutor.html" aria-label="VIM 基础教程"><!---->VIM 基础教程<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="我思"><!--[--><img class="icon" src="/icons/line-md--speedometer-loop.svg" alt aria-hidden no-view style="">我思<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">论文精读</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/thinking/papereading/DS-MoE.html" aria-label="DeepSpeed-MoE 阅读笔记"><!---->DeepSpeed-MoE 阅读笔记<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">我的大学</h4><ul class="vp-dropdown-subitems"></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="我做"><!--[--><img class="icon" src="/icons/line-md--cog-loop.svg" alt aria-hidden no-view style="">我做<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">晋馔雅韵</h4><ul class="vp-dropdown-subitems"></ul></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/stuPETER12138/stuPETER12138.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:none;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:block;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="带我回家"><!---->带我回家<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><!----><span class="vp-sidebar-title">我学</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">VIM 食用指北</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">文档撰写指北</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><!----><span class="vp-sidebar-title">我思</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">窝的大学</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">论文精读</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/thinking/papereading/" aria-label="论文精读"><!---->论文精读<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/thinking/papereading/DS-MoE.html" aria-label="DeepSpeed-MoE 阅读笔记"><!---->DeepSpeed-MoE 阅读笔记<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/thinking/papereading/AI_Oscars.html" aria-label="The Oscars Of AI Theater"><!---->The Oscars Of AI Theater<!----></a></li></ul></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><!----><span class="vp-sidebar-title">我做</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Datawhale AI 夏令营--学习笔记</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">晋馔雅韵</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->The Oscars Of AI Theater</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://stupeter12138.github.io" target="_blank" rel="noopener noreferrer">魔法窝瓜</a></span><span property="author" content="魔法窝瓜"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-11-15T12:16:44.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 3 分钟</span><meta property="timeRequired" content="PT3M"></span><!----><!----></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#data">Data</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#model-and-alignment">Model and alignment</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#agent-architecture">Agent architecture</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#evaluation">Evaluation</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#challenges-and-future-directions">Challenges and Future Directions</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#referances">Referances</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content"><h1 id="the-oscars-of-ai-theater" tabindex="-1"><a class="header-anchor" href="#the-oscars-of-ai-theater"><span>The Oscars Of AI Theater</span></a></h1><p>This practice of aligning LLMs with specific personas or characters is commonly konwn as Role-Playing, aiming to fulfill human needs at a psychological and entertainment level.</p><p><img src="/assets/x1-BlRQJr6Y.png" alt="key components in role-playing" loading="lazy"> key components in role-playing</p><h3 id="data" tabindex="-1"><a class="header-anchor" href="#data"><span><strong>Data</strong></span></a></h3><blockquote><p>diversity and complexity</p></blockquote><p>Commonly, role-playing datasets contain two important components: <strong>interactions</strong> and <strong>role-related information</strong>.</p><figure><img src="/assets/x2-BEPbwuQv.png" alt="x2.png" tabindex="0" loading="lazy"><figcaption>x2.png</figcaption></figure><p>Character-based role-playing scenarios involve simulating a broad spectrum of roles, categorized mainly into two categories: <strong>real world-based</strong> and <strong>virtual scenario-based</strong>.</p><ul><li><p>LLMs as Dta Generator</p></li><li><p>Extracting from Literary Resources</p></li><li><p>Unpublished Resources: <em>role-playing forums</em>(Blue Moon, NationStates, Aryion, ...) <em>online role-playing products</em>, <em>fanfiction communities</em>.</p></li></ul><figure><img src="/assets/Capture_20241111_220103-CcLUFZPk.jpg" alt="Capture_20241111_220103.jpg" tabindex="0" loading="lazy"><figcaption>Capture_20241111_220103.jpg</figcaption></figure><h3 id="model-and-alignment" tabindex="-1"><a class="header-anchor" href="#model-and-alignment"><span><strong>Model and alignment</strong></span></a></h3><blockquote><p>Technically, we divide alignment approaches into Parameter-Tuning: Post-training, Supervised Fine-Tuning (SFT), and Reinforcement Learning; and Parameter-Frozen: In-context learning prompting and Retrieval-Augmented Generation (RAG).</p></blockquote><figure><img src="/assets/Capture_20241111_220205-COs42-XZ.jpg" alt="Capture_20241111_220205.jpg" tabindex="0" loading="lazy"><figcaption>Capture_20241111_220205.jpg</figcaption></figure><p>Foundation models are critical in setting the base capability of role-playing models, which determine <strong>the lower bounds</strong> of performance and sophistication achievable in role-playing scenarios. A crucial step in pre-training an<em>effective foundation model for role-playing</em> involves incorporating <em>a substantial amount of novels</em> into the pretraining corpus, especially those with a worldview distinct from reality.</p><p>Alignment plays a crucial role in defining <strong>the upper limits</strong> of a model&#39;s role-playing ability.</p><ul><li><p>Paramater-Tuning Alignment</p><ul><li><p>Countinue-Pretrain</p></li><li><p>Supervised Fine-Tuning(SFT)</p></li><li><p>Self-Alignment To improve weaker LLM by fine-tuning it on outputs from a stronger LLM.</p></li><li><p>Parameter-Efficiency Fine-Tuning(PEFT) PersonaPKT</p></li><li><p>Reinforcement Learning(RLHF) <a href="https://zhuanlan.zhihu.com/p/624589622" target="_blank" rel="noopener noreferrer">详解大模型RLHF过程（配代码解读）</a></p></li></ul><blockquote><p>The task of annotating high-quality preference data for role-playing is significantly more challenging than for a generic assistant, as it necessitates a deep understanding of the specific character to accurately annotate preferences.</p></blockquote></li><li><p>Paramater-Frozen Alignment</p><ul><li><p>In-Context Learning(ICL) Prompting Typically, filling with role attributes, relations, task requirements within ICL, current LLMs can adapt to different roles swiftly.</p></li><li><p>Retrival Augmented Generation(RAG)</p></li></ul></li></ul><h3 id="agent-architecture" tabindex="-1"><a class="header-anchor" href="#agent-architecture"><span><strong>Agent architecture</strong></span></a></h3><blockquote><p>Effective Role-Playing Language Agents (RPLAs) require a comprehensive system architecture that includes several key modules: <strong>memory</strong>, for recalling and utilizing past interactions; <strong>planning</strong>, for strategic decision-making; and <strong>action</strong>, which encompasses both generating role-related responses and using tools. Such complex architectures ensure RPLAs are not only interactive but also adaptive and context-aware, essential for complex role-playing scenarios.</p></blockquote><p><img src="/assets/Capture_20241111_220224-JhYkxdUx.jpg" alt="The main content flow and categorization of Agent Architecture" loading="lazy"> The main content flow and categorization of Agent Architecture</p><figure><img src="/assets/x3-Hn_ffVYe.png" alt="x3.png" tabindex="0" loading="lazy"><figcaption>x3.png</figcaption></figure><ul><li><p>RPLAs often operate in environments that require them to remember and synthesize information over time, making memory modules an essential component of their architecture.</p></li><li><p>By integrating such sophisticated planning and reflection capabilities, RPLAs can offer more dynamic and engaging experiences in role-play environments.</p></li></ul><p>Agent actions are the culmination of prior planning, memory utilization, and interactions.</p><h3 id="evaluation" tabindex="-1"><a class="header-anchor" href="#evaluation"><span><strong>Evaluation</strong></span></a></h3><blockquote><p>A composite approach, utilizing multiple metrics in tandem, is essential for a comprehensive evaluation.</p></blockquote><ul><li><p>Conversation Ability</p><ul><li><p>Linguistic Quality</p></li><li><p>Coherence</p></li></ul></li><li><p>Role-Rersona Consistency</p><ul><li><p>Attributes</p></li><li><p>Relations</p></li></ul></li><li><p>Role-Behavior Consistency</p><ul><li><p>Conversational Style</p></li><li><p>Personality</p></li><li><p>Linguistic Features</p></li></ul></li><li><p>Role-Playing Attractiveness</p><p>Delta PPL emphasizes the use of relative automatic metrics, to gauge the model&#39;s role-playing capability using triplets like $ (x, y_{win}, y_{lose})$.</p><p>This is the most advanced level, where the role-playing models not only maintain persona and behavioral consistency but also enhances the interaction by being engaging, proactive, and empathetic.</p></li></ul><p>To evaluate role-playing language models on the aforementioned dimensions, existing methods can be categorized into three main types: Reference-based, human-based, and LLM-based evaluation.</p><p><strong>Reference-based metrics</strong> are efficient and objective, providing quick, quantifiable results ideal for preliminary assessments, though they lack depth and context sensitivity, failing to capture nuances like persona consistency. <strong>Human-based evaluations</strong> offer deep insights into nuances and subtleties in dialogues, including character alignment and user engagement, but are costly and less scalable, with potential for subjective variability between evaluators. <strong>LLM-based evaluations</strong>, leveraging the capabilities of large language models, offer scalability and speed and can mimic some aspects of human judgment, yet they may not always align with human evaluations and depend heavily on the used LLMs.</p><h3 id="challenges-and-future-directions" tabindex="-1"><a class="header-anchor" href="#challenges-and-future-directions"><span>Challenges and Future Directions</span></a></h3><ul><li><p>More Reference-based Metrics for evaluating Role-Playing</p></li><li><p>Sensitivity in LLM-Based Evaluation</p></li><li><p>Imbalance, Bias and Cost in Human-based Evaluation</p></li><li><p>Lack of deeper Role-specific Alignment Approaches</p></li><li><p>Ensure the safety in Role-Playing</p></li><li><p>Hallucination in Role-Playing</p></li></ul><p>In general, the advancement of role-playing language models faces numerous challenges, including <strong>the development of specific evaluation metrics</strong>, <strong>efficient memory management</strong>, <strong>ensuring role alignment</strong>, <strong>maintaining safety</strong>, and <strong>facilitating lifelong learning</strong>.</p><h3 id="referances" tabindex="-1"><a class="header-anchor" href="#referances"><span>Referances</span></a></h3><p><a href="https://arxiv.org/abs/2407.11484" target="_blank" rel="noopener noreferrer">The Oscars of AI Theater: A survey on Role-Playing with Language Models</a></p></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/stuPETER12138/stuPETER12138.github.io/edit/main/thinking/papereading/AI_Oscars.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">上次编辑于: </span><!----></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: jio12138@qq.com">Wu</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/thinking/papereading/DS-MoE.html" aria-label="DeepSpeed-MoE 阅读笔记"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->DeepSpeed-MoE 阅读笔记</div></a><!----></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><!----><div class="vp-copyright">MIT 协议 | 版权所有 © 2024 魔法窝瓜</div></footer></div><!--]--><!--]--><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-z8a553x4.js" defer></script>
  </body>
</html>
